name: test | ollama

on:
  workflow_dispatch:
  pull_request:
    types: [ labeled, synchronize ]

jobs:
  setup-ollama:
    runs-on: ubuntu-latest
    services:
      ollama:
        image: ollama/ollama
        ports:
          - 11434:11434

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12.x"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Wait for Ollama to be ready
        run: |
          for i in {1..30}; do
            if curl -s http://localhost:11434/api/tags > /dev/null; then
              echo "Ollama is ready"
              exit 0
            fi
            echo "Waiting for Ollama... attempt $i"
            sleep 2
          done
          echo "Ollama failed to start"
          exit 1

      - name: Pull Models
        run: |
          curl -X POST http://localhost:11434/api/pull -d '{"name": "ollama/llama3.2"}'
          curl -X POST http://localhost:11434/api/pull -d '{"name": "avr/sfr-embedding-mistral:latest"}'

  run_simple_example_test:
    needs: setup-ollama
    runs-on: ubuntu-latest
    services:
      ollama:
        image: ollama/ollama
        ports:
          - 11434:11434

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.x'

      - name: Install Poetry
        uses: snok/install-poetry@v1.4.1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true
          installer-parallel: true

      - name: Install dependencies
        run: |
          poetry install --no-interaction --all-extras

      - name: Install dependencies
        run: |
          poetry install ollama-python requests
          poetry install transformers

      - name: Wait for Ollama to be ready
        run: |
          for i in {1..30}; do
            if curl -s http://localhost:11434/api/tags > /dev/null; then
              echo "Ollama is ready"
              exit 0
            fi
            echo "Waiting for Ollama... attempt $i"
            sleep 2
          done
          echo "Ollama failed to start"
          exit 1

      - name: Dump Docker logs
        run: |
          docker ps
          docker logs $(docker ps --filter "ancestor=ollama/ollama" --format "{{.ID}}")


      - name: Run example test
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GRAPHISTRY_USERNAME: ${{ secrets.GRAPHISTRY_USERNAME }}
          GRAPHISTRY_PASSWORD: ${{ secrets.GRAPHISTRY_PASSWORD }}
          PYTHONFAULTHANDLER: 1
          LLM_API_KEY: "ollama"
          LLM_PROVIDER: "ollama"
          LLM_ENDPOINT: "http://localhost:11434"
          LLM_MODEL: "ollama/llama3.2"
          EMBEDDING_PROVIDER: "ollama"
          EMBEDDING_MODEL: "avr/sfr-embedding-mistral:latest"
          EMBEDDING_ENDPOINT: "http://localhost:11434/api/embeddings"
          EMBEDDING_DIMENSIONS: "4096"
          HUGGINGFACE_TOKENIZER: "Salesforce/SFR-Embedding-Mistral"
        run: poetry run python ./examples/python/simple_example.py