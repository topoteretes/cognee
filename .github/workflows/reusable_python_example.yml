name: test-example

on:
  workflow_call:
    inputs:
      example-location:
        description: "Location of example script to run"
        required: true
        type: string
      arguments:
        description: "Arguments for example script"
        required: false
        type: string
    secrets:
      GRAPHISTRY_USERNAME:
        required: true
      GRAPHISTRY_PASSWORD:
        required: true
      LLM_API_KEY:
        required: true
      OPENAI_API_KEY:
        required: false
      GEMINI_API_KEY:
        required: false
      EMBEDDING_PROVIDER:
        required: false
      EMBEDDING_API_KEY:
        required: false
      EMBEDDING_MODEL:
        required: false
      EMBEDDING_ENDPOINT:
        required: false
      EMBEDDING_API_VERSION:
        required: false
      EMBEDDING_DIMENSIONS:
        required: false
      EMBEDDING_MAX_TOKENS:
        required: false
      LLM_PROVIDER:
        required: false
      LLM_MODEL:
        required: false
      LLM_ENDPOINT:
        required: false
      LLM_API_VERSION:
        required: false

env:
  RUNTIME__LOG_LEVEL: ERROR

jobs:

  run_notebook_test:
    name: test
    runs-on: ubuntu-22.04
    defaults:
      run:
        shell: bash
    steps:
      - name: Check out
        uses: actions/checkout@master

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12.x'

      - name: Install Poetry
        uses: snok/install-poetry@v1.4.1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true
          installer-parallel: true

      - name: Install dependencies
        run: |
          poetry install --no-interaction --all-extras

      - name: Install Gemini dependencies
        if: ${{ contains(inputs.arguments, '--llm_provider=gemini') || env.LLM_PROVIDER == 'gemini' }}
        run: |
          poetry add google-generativeai

      - name: Parse Arguments to Environment Variables
        if: ${{ inputs.arguments != '' }}
        run: |
          args="${{ inputs.arguments }}"
          # Extract embedding provider
          if [[ $args == *"--embedding_provider="* ]]; then
            EMBEDDING_PROVIDER=$(echo $args | grep -o "\--embedding_provider=[^ ]*" | cut -d'=' -f2)
            echo "EMBEDDING_PROVIDER=$EMBEDDING_PROVIDER" >> $GITHUB_ENV
          fi
          # Extract embedding model
          if [[ $args == *"--embedding_model="* ]]; then
            EMBEDDING_MODEL=$(echo $args | grep -o "\--embedding_model=[^ ]*" | cut -d'=' -f2)
            echo "EMBEDDING_MODEL=$EMBEDDING_MODEL" >> $GITHUB_ENV
          fi
          # Extract embedding endpoint
          if [[ $args == *"--embedding_endpoint="* ]]; then
            EMBEDDING_ENDPOINT=$(echo $args | grep -o "\--embedding_endpoint=[^ ]*" | cut -d'=' -f2)
            echo "EMBEDDING_ENDPOINT=$EMBEDDING_ENDPOINT" >> $GITHUB_ENV
          fi
          # Extract embedding API version
          if [[ $args == *"--embedding_api_version="* ]]; then
            EMBEDDING_API_VERSION=$(echo $args | grep -o "\--embedding_api_version=[^ ]*" | cut -d'=' -f2)
            echo "EMBEDDING_API_VERSION=$EMBEDDING_API_VERSION" >> $GITHUB_ENV
          fi
          # Extract embedding dimensions
          if [[ $args == *"--embedding_dimensions="* ]]; then
            EMBEDDING_DIMENSIONS=$(echo $args | grep -o "\--embedding_dimensions=[^ ]*" | cut -d'=' -f2)
            echo "EMBEDDING_DIMENSIONS=$EMBEDDING_DIMENSIONS" >> $GITHUB_ENV
          fi
          # Extract embedding max tokens
          if [[ $args == *"--embedding_max_tokens="* ]]; then
            EMBEDDING_MAX_TOKENS=$(echo $args | grep -o "\--embedding_max_tokens=[^ ]*" | cut -d'=' -f2)
            echo "EMBEDDING_MAX_TOKENS=$EMBEDDING_MAX_TOKENS" >> $GITHUB_ENV
          fi
          # Extract LLM provider
          if [[ $args == *"--llm_provider="* ]]; then
            LLM_PROVIDER=$(echo $args | grep -o "\--llm_provider=[^ ]*" | cut -d'=' -f2)
            echo "LLM_PROVIDER=$LLM_PROVIDER" >> $GITHUB_ENV
          fi
          # Extract LLM model
          if [[ $args == *"--llm_model="* ]]; then
            LLM_MODEL=$(echo $args | grep -o "\--llm_model=[^ ]*" | cut -d'=' -f2)
            echo "LLM_MODEL=$LLM_MODEL" >> $GITHUB_ENV
          fi
          # Extract LLM endpoint
          if [[ $args == *"--llm_endpoint="* ]]; then
            LLM_ENDPOINT=$(echo $args | grep -o "\--llm_endpoint=[^ ]*" | cut -d'=' -f2)
            echo "LLM_ENDPOINT=$LLM_ENDPOINT" >> $GITHUB_ENV
          fi
          # Extract LLM API version
          if [[ $args == *"--llm_api_version="* ]]; then
            LLM_API_VERSION=$(echo $args | grep -o "\--llm_api_version=[^ ]*" | cut -d'=' -f2)
            echo "LLM_API_VERSION=$LLM_API_VERSION" >> $GITHUB_ENV
          fi

      - name: Execute Python Example
        env:
          ENV: 'dev'
          PYTHONFAULTHANDLER: 1
          LLM_PROVIDER: ${{ secrets.LLM_PROVIDER }}
          LLM_MODEL: ${{ secrets.LLM_MODEL }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_ENDPOINT: ${{ secrets.LLM_ENDPOINT }}
          LLM_API_VERSION: ${{ secrets.LLM_API_VERSION }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          GRAPHISTRY_USERNAME: ${{ secrets.GRAPHISTRY_USERNAME }}
          GRAPHISTRY_PASSWORD: ${{ secrets.GRAPHISTRY_PASSWORD }}
          EMBEDDING_PROVIDER: ${{ secrets.EMBEDDING_PROVIDER }}
          EMBEDDING_MODEL: ${{ secrets.EMBEDDING_MODEL }}
          EMBEDDING_API_KEY: ${{ secrets.EMBEDDING_API_KEY }}
          EMBEDDING_ENDPOINT: ${{ secrets.EMBEDDING_ENDPOINT }}
          EMBEDDING_API_VERSION: ${{ secrets.EMBEDDING_API_VERSION }}
          EMBEDDING_DIMENSIONS: ${{ secrets.EMBEDDING_DIMENSIONS }}
          EMBEDDING_MAX_TOKENS: ${{ secrets.EMBEDDING_MAX_TOKENS }}
        run: |
          echo "Running example with provider: $LLM_PROVIDER model: $LLM_MODEL"
          poetry run python ${{ inputs.example-location }} ${{ inputs.arguments }}
