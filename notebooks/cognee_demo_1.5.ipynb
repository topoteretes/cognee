{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958375a6ffc0c2e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:47.336283Z",
     "start_time": "2024-09-20T14:02:43.652444Z"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "from typing import Union\n",
    "\n",
    "from cognee.modules.cognify.config import get_cognify_config\n",
    "from cognee.shared.data_models import KnowledgeGraph\n",
    "from cognee.modules.data.models import Dataset, Data\n",
    "from cognee.modules.data.methods.get_dataset_data import get_dataset_data\n",
    "from cognee.modules.data.methods import get_datasets, get_datasets_by_name\n",
    "from cognee.modules.pipelines.tasks.Task import Task\n",
    "from cognee.modules.pipelines import run_tasks, run_tasks_parallel\n",
    "from cognee.modules.users.models import User\n",
    "from cognee.modules.users.methods import get_default_user\n",
    "from cognee.modules.pipelines.operations.get_pipeline_status import get_pipeline_status\n",
    "from cognee.modules.pipelines.operations.log_pipeline_status import log_pipeline_status\n",
    "from cognee.tasks import chunk_extract_summary, \\\n",
    "    chunk_naive_llm_classifier, \\\n",
    "    chunk_remove_disconnected, \\\n",
    "    infer_data_ontology, \\\n",
    "    save_chunks_to_store, \\\n",
    "    chunk_update_check, \\\n",
    "    chunks_into_graph, \\\n",
    "    source_documents_to_chunks, \\\n",
    "    check_permissions_on_documents, \\\n",
    "    classify_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df16431d0f48b006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:48.519686Z",
     "start_time": "2024-09-20T14:02:48.515589Z"
    }
   },
   "outputs": [],
   "source": [
    "job_position = \"\"\"Senior Data Scientist (Machine Learning)\n",
    "\n",
    "Company: TechNova Solutions\n",
    "Location: San Francisco, CA\n",
    "\n",
    "Job Description:\n",
    "\n",
    "TechNova Solutions is seeking a Senior Data Scientist specializing in Machine Learning to join our dynamic analytics team. The ideal candidate will have a strong background in developing and deploying machine learning models, working with large datasets, and translating complex data into actionable insights.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Develop and implement advanced machine learning algorithms and models.\n",
    "Analyze large, complex datasets to extract meaningful patterns and insights.\n",
    "Collaborate with cross-functional teams to integrate predictive models into products.\n",
    "Stay updated with the latest advancements in machine learning and data science.\n",
    "Mentor junior data scientists and provide technical guidance.\n",
    "Qualifications:\n",
    "\n",
    "Master’s or Ph.D. in Data Science, Computer Science, Statistics, or a related field.\n",
    "5+ years of experience in data science and machine learning.\n",
    "Proficient in Python, R, and SQL.\n",
    "Experience with deep learning frameworks (e.g., TensorFlow, PyTorch).\n",
    "Strong problem-solving skills and attention to detail.\n",
    "Candidate CVs\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9086abf3af077ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:49.120838Z",
     "start_time": "2024-09-20T14:02:49.118294Z"
    }
   },
   "outputs": [],
   "source": [
    "job_1 = \"\"\"\n",
    "CV 1: Relevant\n",
    "Name: Dr. Emily Carter\n",
    "Contact Information:\n",
    "\n",
    "Email: emily.carter@example.com\n",
    "Phone: (555) 123-4567\n",
    "Summary:\n",
    "\n",
    "Senior Data Scientist with over 8 years of experience in machine learning and predictive analytics. Expertise in developing advanced algorithms and deploying scalable models in production environments.\n",
    "\n",
    "Education:\n",
    "\n",
    "Ph.D. in Computer Science, Stanford University (2014)\n",
    "B.S. in Mathematics, University of California, Berkeley (2010)\n",
    "Experience:\n",
    "\n",
    "Senior Data Scientist, InnovateAI Labs (2016 – Present)\n",
    "Led a team in developing machine learning models for natural language processing applications.\n",
    "Implemented deep learning algorithms that improved prediction accuracy by 25%.\n",
    "Collaborated with cross-functional teams to integrate models into cloud-based platforms.\n",
    "Data Scientist, DataWave Analytics (2014 – 2016)\n",
    "Developed predictive models for customer segmentation and churn analysis.\n",
    "Analyzed large datasets using Hadoop and Spark frameworks.\n",
    "Skills:\n",
    "\n",
    "Programming Languages: Python, R, SQL\n",
    "Machine Learning: TensorFlow, Keras, Scikit-Learn\n",
    "Big Data Technologies: Hadoop, Spark\n",
    "Data Visualization: Tableau, Matplotlib\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9de0cc07f798b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:49.675003Z",
     "start_time": "2024-09-20T14:02:49.671615Z"
    }
   },
   "outputs": [],
   "source": [
    "job_2 = \"\"\"\n",
    "CV 2: Relevant\n",
    "Name: Michael Rodriguez\n",
    "Contact Information:\n",
    "\n",
    "Email: michael.rodriguez@example.com\n",
    "Phone: (555) 234-5678\n",
    "Summary:\n",
    "\n",
    "Data Scientist with a strong background in machine learning and statistical modeling. Skilled in handling large datasets and translating data into actionable business insights.\n",
    "\n",
    "Education:\n",
    "\n",
    "M.S. in Data Science, Carnegie Mellon University (2013)\n",
    "B.S. in Computer Science, University of Michigan (2011)\n",
    "Experience:\n",
    "\n",
    "Senior Data Scientist, Alpha Analytics (2017 – Present)\n",
    "Developed machine learning models to optimize marketing strategies.\n",
    "Reduced customer acquisition cost by 15% through predictive modeling.\n",
    "Data Scientist, TechInsights (2013 – 2017)\n",
    "Analyzed user behavior data to improve product features.\n",
    "Implemented A/B testing frameworks to evaluate product changes.\n",
    "Skills:\n",
    "\n",
    "Programming Languages: Python, Java, SQL\n",
    "Machine Learning: Scikit-Learn, XGBoost\n",
    "Data Visualization: Seaborn, Plotly\n",
    "Databases: MySQL, MongoDB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "185ff1c102d06111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:50.286828Z",
     "start_time": "2024-09-20T14:02:50.284369Z"
    }
   },
   "outputs": [],
   "source": [
    "job_3 = \"\"\"\n",
    "CV 3: Relevant\n",
    "Name: Sarah Nguyen\n",
    "Contact Information:\n",
    "\n",
    "Email: sarah.nguyen@example.com\n",
    "Phone: (555) 345-6789\n",
    "Summary:\n",
    "\n",
    "Data Scientist specializing in machine learning with 6 years of experience. Passionate about leveraging data to drive business solutions and improve product performance.\n",
    "\n",
    "Education:\n",
    "\n",
    "M.S. in Statistics, University of Washington (2014)\n",
    "B.S. in Applied Mathematics, University of Texas at Austin (2012)\n",
    "Experience:\n",
    "\n",
    "Data Scientist, QuantumTech (2016 – Present)\n",
    "Designed and implemented machine learning algorithms for financial forecasting.\n",
    "Improved model efficiency by 20% through algorithm optimization.\n",
    "Junior Data Scientist, DataCore Solutions (2014 – 2016)\n",
    "Assisted in developing predictive models for supply chain optimization.\n",
    "Conducted data cleaning and preprocessing on large datasets.\n",
    "Skills:\n",
    "\n",
    "Programming Languages: Python, R\n",
    "Machine Learning Frameworks: PyTorch, Scikit-Learn\n",
    "Statistical Analysis: SAS, SPSS\n",
    "Cloud Platforms: AWS, Azure\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55ce4c58f8efb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:50.950343Z",
     "start_time": "2024-09-20T14:02:50.946378Z"
    }
   },
   "outputs": [],
   "source": [
    "job_4 = \"\"\"\n",
    "CV 4: Not Relevant\n",
    "Name: David Thompson\n",
    "Contact Information:\n",
    "\n",
    "Email: david.thompson@example.com\n",
    "Phone: (555) 456-7890\n",
    "Summary:\n",
    "\n",
    "Creative Graphic Designer with over 8 years of experience in visual design and branding. Proficient in Adobe Creative Suite and passionate about creating compelling visuals.\n",
    "\n",
    "Education:\n",
    "\n",
    "B.F.A. in Graphic Design, Rhode Island School of Design (2012)\n",
    "Experience:\n",
    "\n",
    "Senior Graphic Designer, CreativeWorks Agency (2015 – Present)\n",
    "Led design projects for clients in various industries.\n",
    "Created branding materials that increased client engagement by 30%.\n",
    "Graphic Designer, Visual Innovations (2012 – 2015)\n",
    "Designed marketing collateral, including brochures, logos, and websites.\n",
    "Collaborated with the marketing team to develop cohesive brand strategies.\n",
    "Skills:\n",
    "\n",
    "Design Software: Adobe Photoshop, Illustrator, InDesign\n",
    "Web Design: HTML, CSS\n",
    "Specialties: Branding and Identity, Typography\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4ecc32721ad332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:51.548191Z",
     "start_time": "2024-09-20T14:02:51.545520Z"
    }
   },
   "outputs": [],
   "source": [
    "job_5 = \"\"\"\n",
    "CV 5: Not Relevant\n",
    "Name: Jessica Miller\n",
    "Contact Information:\n",
    "\n",
    "Email: jessica.miller@example.com\n",
    "Phone: (555) 567-8901\n",
    "Summary:\n",
    "\n",
    "Experienced Sales Manager with a strong track record in driving sales growth and building high-performing teams. Excellent communication and leadership skills.\n",
    "\n",
    "Education:\n",
    "\n",
    "B.A. in Business Administration, University of Southern California (2010)\n",
    "Experience:\n",
    "\n",
    "Sales Manager, Global Enterprises (2015 – Present)\n",
    "Managed a sales team of 15 members, achieving a 20% increase in annual revenue.\n",
    "Developed sales strategies that expanded customer base by 25%.\n",
    "Sales Representative, Market Leaders Inc. (2010 – 2015)\n",
    "Consistently exceeded sales targets and received the 'Top Salesperson' award in 2013.\n",
    "Skills:\n",
    "\n",
    "Sales Strategy and Planning\n",
    "Team Leadership and Development\n",
    "CRM Software: Salesforce, Zoho\n",
    "Negotiation and Relationship Building\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "904df61ba484a8e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:54.243987Z",
     "start_time": "2024-09-20T14:02:52.498195Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: SAWarning: TypeDecorator UUID() will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this warning at: https://sqlalche.me/e/20/cprf)\n",
      "Coroutine task errored: `ingest_data`\n",
      "Pipeline execution failed at stage sync with exception:\n",
      "\n",
      "<class 'sqlalchemy.exc.NoSuchModuleError'>\n",
      "Can't load plugin: sqlalchemy.dialects:postgres\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 742, in sync_destination\n",
      "    remote_state = self._restore_state_from_destination()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 1483, in _restore_state_from_destination\n",
      "    with self._get_destination_clients(schema)[0] as job_client:\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 1244, in _get_destination_clients\n",
      "    client = self.destination.client(schema, initial_config)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/common/destination/reference.py\", line 748, in client\n",
      "    return self.client_class(schema, config, self.capabilities(config, schema.naming))\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/common/destination/reference.py\", line 702, in capabilities\n",
      "    return self.adjust_capabilities(caps, config, naming)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/factory.py\", line 60, in adjust_capabilities\n",
      "    dialect = config.get_dialect()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/configuration.py\", line 63, in get_dialect\n",
      "    return self.credentials.get_dialect()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/configuration.py\", line 50, in get_dialect\n",
      "    return self.to_url().get_dialect()  # type: ignore[attr-defined,no-any-return]\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/engine/url.py\", line 776, in get_dialect\n",
      "    entrypoint = self._get_entrypoint()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/engine/url.py\", line 758, in _get_entrypoint\n",
      "    cls = registry.load(name)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 375, in load\n",
      "    raise exc.NoSuchModuleError(\n",
      "sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:postgres\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py\", line 112, in run_tasks_base\n",
      "    task_result = await running_task.run(*args)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/tasks/ingestion/ingest_data.py\", line 84, in ingest_data\n",
      "    run_info = pipeline.run(\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 223, in _wrap\n",
      "    step_info = f(self, *args, **kwargs)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 268, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 681, in run\n",
      "    self.sync_destination(destination, staging, dataset_name)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 177, in _wrap\n",
      "    rv = f(self, *args, **kwargs)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 811, in sync_destination\n",
      "    raise PipelineStepFailed(self, \"sync\", None, ex, None) from ex\n",
      "dlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at stage sync with exception:\n",
      "\n",
      "<class 'sqlalchemy.exc.NoSuchModuleError'>\n",
      "Can't load plugin: sqlalchemy.dialects:postgresFunction task errored: `save_data_to_storage`\n",
      "Pipeline execution failed at stage sync with exception:\n",
      "\n",
      "<class 'sqlalchemy.exc.NoSuchModuleError'>\n",
      "Can't load plugin: sqlalchemy.dialects:postgres\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 742, in sync_destination\n",
      "    remote_state = self._restore_state_from_destination()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 1483, in _restore_state_from_destination\n",
      "    with self._get_destination_clients(schema)[0] as job_client:\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 1244, in _get_destination_clients\n",
      "    client = self.destination.client(schema, initial_config)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/common/destination/reference.py\", line 748, in client\n",
      "    return self.client_class(schema, config, self.capabilities(config, schema.naming))\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/common/destination/reference.py\", line 702, in capabilities\n",
      "    return self.adjust_capabilities(caps, config, naming)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/factory.py\", line 60, in adjust_capabilities\n",
      "    dialect = config.get_dialect()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/configuration.py\", line 63, in get_dialect\n",
      "    return self.credentials.get_dialect()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/configuration.py\", line 50, in get_dialect\n",
      "    return self.to_url().get_dialect()  # type: ignore[attr-defined,no-any-return]\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/engine/url.py\", line 776, in get_dialect\n",
      "    entrypoint = self._get_entrypoint()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/engine/url.py\", line 758, in _get_entrypoint\n",
      "    cls = registry.load(name)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 375, in load\n",
      "    raise exc.NoSuchModuleError(\n",
      "sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:postgres\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py\", line 141, in run_tasks_base\n",
      "    async for result in run_tasks_base(leftover_tasks, task_result, user):\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py\", line 131, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py\", line 112, in run_tasks_base\n",
      "    task_result = await running_task.run(*args)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/tasks/ingestion/ingest_data.py\", line 84, in ingest_data\n",
      "    run_info = pipeline.run(\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 223, in _wrap\n",
      "    step_info = f(self, *args, **kwargs)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 268, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 681, in run\n",
      "    self.sync_destination(destination, staging, dataset_name)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 177, in _wrap\n",
      "    rv = f(self, *args, **kwargs)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 811, in sync_destination\n",
      "    raise PipelineStepFailed(self, \"sync\", None, ex, None) from ex\n",
      "dlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at stage sync with exception:\n",
      "\n",
      "<class 'sqlalchemy.exc.NoSuchModuleError'>\n",
      "Can't load plugin: sqlalchemy.dialects:postgresPipeline run errored: `add_pipeline`\n",
      "Pipeline execution failed at stage sync with exception:\n",
      "\n",
      "<class 'sqlalchemy.exc.NoSuchModuleError'>\n",
      "Can't load plugin: sqlalchemy.dialects:postgres\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 742, in sync_destination\n",
      "    remote_state = self._restore_state_from_destination()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 1483, in _restore_state_from_destination\n",
      "    with self._get_destination_clients(schema)[0] as job_client:\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 1244, in _get_destination_clients\n",
      "    client = self.destination.client(schema, initial_config)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/common/destination/reference.py\", line 748, in client\n",
      "    return self.client_class(schema, config, self.capabilities(config, schema.naming))\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/common/destination/reference.py\", line 702, in capabilities\n",
      "    return self.adjust_capabilities(caps, config, naming)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/factory.py\", line 60, in adjust_capabilities\n",
      "    dialect = config.get_dialect()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/configuration.py\", line 63, in get_dialect\n",
      "    return self.credentials.get_dialect()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/configuration.py\", line 50, in get_dialect\n",
      "    return self.to_url().get_dialect()  # type: ignore[attr-defined,no-any-return]\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/engine/url.py\", line 776, in get_dialect\n",
      "    entrypoint = self._get_entrypoint()\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/engine/url.py\", line 758, in _get_entrypoint\n",
      "    cls = registry.load(name)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 375, in load\n",
      "    raise exc.NoSuchModuleError(\n",
      "sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:postgres\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py\", line 169, in run_tasks\n",
      "    async for result in run_tasks_base(tasks, data, user):\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py\", line 158, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py\", line 141, in run_tasks_base\n",
      "    async for result in run_tasks_base(leftover_tasks, task_result, user):\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py\", line 131, in run_tasks_base\n",
      "    raise error\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py\", line 112, in run_tasks_base\n",
      "    task_result = await running_task.run(*args)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/cognee/tasks/ingestion/ingest_data.py\", line 84, in ingest_data\n",
      "    run_info = pipeline.run(\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 223, in _wrap\n",
      "    step_info = f(self, *args, **kwargs)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 268, in _wrap\n",
      "    return f(self, *args, **kwargs)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 681, in run\n",
      "    self.sync_destination(destination, staging, dataset_name)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 177, in _wrap\n",
      "    rv = f(self, *args, **kwargs)\n",
      "  File \"/Users/borisarzentar/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py\", line 811, in sync_destination\n",
      "    raise PipelineStepFailed(self, \"sync\", None, ex, None) from ex\n",
      "dlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at stage sync with exception:\n",
      "\n",
      "<class 'sqlalchemy.exc.NoSuchModuleError'>\n",
      "Can't load plugin: sqlalchemy.dialects:postgres"
     ]
    },
    {
     "ename": "PipelineStepFailed",
     "evalue": "Pipeline execution failed at stage sync with exception:\n\n<class 'sqlalchemy.exc.NoSuchModuleError'>\nCan't load plugin: sqlalchemy.dialects:postgres",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchModuleError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:742\u001b[0m, in \u001b[0;36mPipeline.sync_destination\u001b[0;34m(self, destination, staging, dataset_name)\u001b[0m\n\u001b[1;32m    740\u001b[0m restored_schemas: Sequence[Schema] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 742\u001b[0m remote_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_state_from_destination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# if remote state is newer or same\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# print(f'REMOTE STATE: {(remote_state or {}).get(\"_state_version\")} >= {state[\"_state_version\"]}')\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# TODO: check if remote_state[\"_state_version\"] is not in 10 recent version. then we know remote is newer.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:1483\u001b[0m, in \u001b[0;36mPipeline._restore_state_from_destination\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1482\u001b[0m     schema \u001b[38;5;241m=\u001b[39m Schema(schema_name)\n\u001b[0;32m-> 1483\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_destination_clients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mas\u001b[39;00m job_client:\n\u001b[1;32m   1484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job_client, WithStateSync):\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:1244\u001b[0m, in \u001b[0;36mPipeline._get_destination_clients\u001b[0;34m(self, schema, initial_config, initial_staging_config)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;66;03m# create instance with initial_config properly set\u001b[39;00m\n\u001b[0;32m-> 1244\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client, staging_client\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/common/destination/reference.py:748\u001b[0m, in \u001b[0;36mDestination.client\u001b[0;34m(self, schema, initial_config)\u001b[0m\n\u001b[1;32m    747\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration(initial_config)\n\u001b[0;32m--> 748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_class(schema, config, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnaming\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/common/destination/reference.py:702\u001b[0m, in \u001b[0;36mDestination.capabilities\u001b[0;34m(self, config, naming)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_capabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnaming\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/factory.py:60\u001b[0m, in \u001b[0;36msqlalchemy.adjust_capabilities\u001b[0;34m(cls, caps, config, naming)\u001b[0m\n\u001b[1;32m     59\u001b[0m caps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(sqlalchemy, \u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39madjust_capabilities(caps, config, naming)\n\u001b[0;32m---> 60\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dialect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dialect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/configuration.py:63\u001b[0m, in \u001b[0;36mSqlalchemyClientConfiguration.get_dialect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dialect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Type[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDialect\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dialect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/destinations/impl/sqlalchemy/configuration.py:50\u001b[0m, in \u001b[0;36mSqlalchemyCredentials.get_dialect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(engine\u001b[38;5;241m.\u001b[39mdialect)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dialect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/engine/url.py:776\u001b[0m, in \u001b[0;36mURL.get_dialect\u001b[0;34m(self, _is_async)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the SQLAlchemy :class:`_engine.Dialect` class corresponding\u001b[39;00m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;124;03mto this URL's driver name.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \n\u001b[1;32m    775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m entrypoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_entrypoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_async:\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/engine/url.py:758\u001b[0m, in \u001b[0;36mURL._get_entrypoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrivername\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 758\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;66;03m# check for legacy dialects that\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;66;03m# would return a module with 'dialect' as the\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;66;03m# actual class\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py:375\u001b[0m, in \u001b[0;36mPluginLoader.load\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m--> 375\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mNoSuchModuleError(\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load plugin: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup, name)\n\u001b[1;32m    377\u001b[0m )\n",
      "\u001b[0;31mNoSuchModuleError\u001b[0m: Can't load plugin: sqlalchemy.dialects:postgres",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m listdir, path\n\u001b[1;32m      4\u001b[0m data_path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m cognee\u001b[38;5;241m.\u001b[39madd([job_1, job_2,job_3,job_4,job_5,job_position], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/cognee/api/v1/add/add_v2.py:21\u001b[0m, in \u001b[0;36madd\u001b[0;34m(data, dataset_name, user)\u001b[0m\n\u001b[1;32m     14\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     15\u001b[0m     Task(save_data_to_storage, dataset_name),\n\u001b[1;32m     16\u001b[0m     Task(ingest_data, dataset_name, user)\n\u001b[1;32m     17\u001b[0m ]\n\u001b[1;32m     19\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m run_tasks(tasks, data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m pipeline:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py:187\u001b[0m, in \u001b[0;36mrun_tasks\u001b[0;34m(tasks, data, pipeline_name)\u001b[0m\n\u001b[1;32m    177\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline run errored: `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    179\u001b[0m     pipeline_name,\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mstr\u001b[39m(error),\n\u001b[1;32m    181\u001b[0m     exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m )\n\u001b[1;32m    183\u001b[0m send_telemetry(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline Run Errored\u001b[39m\u001b[38;5;124m\"\u001b[39m, user\u001b[38;5;241m.\u001b[39mid, {\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: pipeline_name,\n\u001b[1;32m    185\u001b[0m })\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py:169\u001b[0m, in \u001b[0;36mrun_tasks\u001b[0;34m(tasks, data, pipeline_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline run started: `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m, pipeline_name)\n\u001b[1;32m    165\u001b[0m send_telemetry(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline Run Started\u001b[39m\u001b[38;5;124m\"\u001b[39m, user\u001b[38;5;241m.\u001b[39mid, {\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: pipeline_name,\n\u001b[1;32m    167\u001b[0m })\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m run_tasks_base(tasks, data, user):\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m result\n\u001b[1;32m    172\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline run completed: `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m, pipeline_name)\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py:158\u001b[0m, in \u001b[0;36mrun_tasks_base\u001b[0;34m(tasks, data, user)\u001b[0m\n\u001b[1;32m    149\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction task errored: `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m     running_task\u001b[38;5;241m.\u001b[39mexecutable\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mstr\u001b[39m(error),\n\u001b[1;32m    153\u001b[0m     exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    154\u001b[0m )\n\u001b[1;32m    155\u001b[0m send_telemetry(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction Task Errored\u001b[39m\u001b[38;5;124m\"\u001b[39m, user\u001b[38;5;241m.\u001b[39mid, {\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: running_task\u001b[38;5;241m.\u001b[39mexecutable\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    157\u001b[0m })\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py:141\u001b[0m, in \u001b[0;36mrun_tasks_base\u001b[0;34m(tasks, data, user)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     task_result \u001b[38;5;241m=\u001b[39m running_task\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m run_tasks_base(leftover_tasks, task_result, user):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m result\n\u001b[1;32m    144\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction task completed: `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m, running_task\u001b[38;5;241m.\u001b[39mexecutable\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py:131\u001b[0m, in \u001b[0;36mrun_tasks_base\u001b[0;34m(tasks, data, user)\u001b[0m\n\u001b[1;32m    122\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoroutine task errored: `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    124\u001b[0m             running_task\u001b[38;5;241m.\u001b[39mexecutable\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28mstr\u001b[39m(error),\n\u001b[1;32m    126\u001b[0m             exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    127\u001b[0m         )\n\u001b[1;32m    128\u001b[0m         send_telemetry(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoroutine Task Errored\u001b[39m\u001b[38;5;124m\"\u001b[39m, user\u001b[38;5;241m.\u001b[39mid, {\n\u001b[1;32m    129\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: running_task\u001b[38;5;241m.\u001b[39mexecutable\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    130\u001b[0m         })\n\u001b[0;32m--> 131\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(running_task\u001b[38;5;241m.\u001b[39mexecutable):\n\u001b[1;32m    134\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction task started: `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m, running_task\u001b[38;5;241m.\u001b[39mexecutable\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/cognee/modules/pipelines/operations/run_tasks.py:112\u001b[0m, in \u001b[0;36mrun_tasks_base\u001b[0;34m(tasks, data, user)\u001b[0m\n\u001b[1;32m    108\u001b[0m send_telemetry(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoroutine Task Started\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_id \u001b[38;5;241m=\u001b[39m user\u001b[38;5;241m.\u001b[39mid, additional_properties \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: running_task\u001b[38;5;241m.\u001b[39mexecutable\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    110\u001b[0m })\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     task_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m running_task\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m run_tasks_base(leftover_tasks, task_result, user):\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m result\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/cognee/tasks/ingestion/ingest_data.py:84\u001b[0m, in \u001b[0;36mingest_data\u001b[0;34m(file_paths, dataset_name, user)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m give_permission_on_document(user, data_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m send_telemetry(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcognee.add EXECUTION STARTED\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_id \u001b[38;5;241m=\u001b[39m user\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m---> 84\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_resources\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_metadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmerge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m send_telemetry(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcognee.add EXECUTION COMPLETED\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_id \u001b[38;5;241m=\u001b[39m user\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_info\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:223\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    221\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 223\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:268\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    266\u001b[0m         ConfigSectionContext(pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections)\n\u001b[1;32m    267\u001b[0m     ):\n\u001b[0;32m--> 268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:681\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, table_format, schema_contract, refresh)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# sync state with destination\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrestore_from_destination\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev_mode\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_restored\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdestination \u001b[38;5;129;01mor\u001b[39;00m destination)\n\u001b[1;32m    680\u001b[0m ):\n\u001b[0;32m--> 681\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_destination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstaging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;66;03m# sync only once\u001b[39;00m\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_restored \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:177\u001b[0m, in \u001b[0;36mwith_schemas_sync.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mcommit_live_schema(name)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# because we committed live schema before calling f, we may safely\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# drop all changes in live schemas\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_storage\u001b[38;5;241m.\u001b[39mlive_schemas\u001b[38;5;241m.\u001b[39mkeys()):\n",
      "File \u001b[0;32m~/Projects/Topoteretes/cognee/.venv/lib/python3.9/site-packages/dlt/pipeline/pipeline.py:811\u001b[0m, in \u001b[0;36mPipeline.sync_destination\u001b[0;34m(self, destination, staging, dataset_name)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_state(state)\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineStepFailed(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msync\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, ex, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m: Pipeline execution failed at stage sync with exception:\n\n<class 'sqlalchemy.exc.NoSuchModuleError'>\nCan't load plugin: sqlalchemy.dialects:postgres"
     ]
    }
   ],
   "source": [
    "import cognee\n",
    "from os import listdir, path\n",
    "\n",
    "data_path = path.abspath(\".data\")\n",
    "\n",
    "await cognee.add([job_1, job_2,job_3,job_4,job_5,job_position], \"example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9b564de121713d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:55.564445Z",
     "start_time": "2024-09-20T14:02:55.562784Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8911f8bd4f8c440a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:56.714408Z",
     "start_time": "2024-09-20T14:02:56.711812Z"
    }
   },
   "outputs": [],
   "source": [
    "# from enum import Enum, auto\n",
    "# from typing import Optional, List, Union, Dict, Any\n",
    "# from pydantic import BaseModel, Field\n",
    "# \n",
    "# class Node(BaseModel):\n",
    "#     \"\"\"Node in a knowledge graph.\"\"\"\n",
    "#     id: str\n",
    "#     name: str\n",
    "#     type: str\n",
    "#     description: str\n",
    "#     properties: Optional[Dict[str, Any]] = Field(None, description = \"A dictionary of properties associated with the node.\")\n",
    "# \n",
    "# class Edge(BaseModel):\n",
    "#     \"\"\"Edge in a knowledge graph.\"\"\"\n",
    "#     source_node_id: str\n",
    "#     target_node_id: str\n",
    "#     relationship_name: str\n",
    "#     properties: Optional[Dict[str, Any]] = Field(None, description = \"A dictionary of properties associated with the edge.\")\n",
    "# \n",
    "# class KnowledgeGraph(BaseModel):\n",
    "#     \"\"\"Knowledge graph.\"\"\"\n",
    "#     nodes: List[Node] = Field(..., default_factory=list)\n",
    "#     edges: List[Edge] = Field(..., default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c431fdef4921ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:57.925667Z",
     "start_time": "2024-09-20T14:02:57.922353Z"
    }
   },
   "outputs": [],
   "source": [
    "async def run_cognify_pipeline(dataset: Dataset, user: User = None):\n",
    "    data_documents: list[Data] = await get_dataset_data(dataset_id = dataset.id)\n",
    "\n",
    "    try:\n",
    "\n",
    "        root_node_id = None\n",
    "\n",
    "        tasks = [\n",
    "            Task(classify_documents),\n",
    "            Task(check_permissions_on_documents, user = user, permissions = [\"write\"]),\n",
    "            Task(infer_data_ontology, root_node_id = root_node_id, ontology_model = KnowledgeGraph),\n",
    "            Task(source_documents_to_chunks, chunk_size = 800, parent_node_id = root_node_id), # Classify documents and save them as a nodes in graph db, extract text chunks based on the document type\n",
    "            Task(chunks_into_graph, graph_model = KnowledgeGraph, collection_name = \"entities\", task_config = { \"batch_size\": 10 }), # Generate knowledge graphs from the document chunks and attach it to chunk nodes\n",
    "            Task(chunk_update_check, collection_name = \"chunks\"), # Find all affected chunks, so we don't process unchanged chunks\n",
    "            Task(\n",
    "                save_chunks_to_store,\n",
    "                collection_name = \"chunks\",\n",
    "            ), \n",
    "            Task(chunk_remove_disconnected), # Remove the obsolete document chunks.\n",
    "        ]\n",
    "\n",
    "        pipeline = run_tasks(tasks, data_documents)\n",
    "\n",
    "        async for result in pipeline:\n",
    "            print(result)\n",
    "    except Exception as error:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a91b99c6215e09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:02:58.905774Z",
     "start_time": "2024-09-20T14:02:58.625915Z"
    }
   },
   "outputs": [],
   "source": [
    "user = await get_default_user()\n",
    "datasets = await get_datasets_by_name([\"example\"], user.id)\n",
    "await run_cognify_pipeline(datasets[0], user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080389e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cognee.shared.utils import render_graph\n",
    "from cognee.infrastructure.databases.graph import get_graph_engine\n",
    "import graphistry\n",
    "\n",
    "# # Setting an environment variable\n",
    "# os.environ[\"GRAPHISTRY_USERNAME\"] = placeholder\n",
    "# os.environ[\"GRAPHISTRY_PASSWORD\"] = placeholder\n",
    "\n",
    "\n",
    "graphistry.login(username=os.getenv(\"GRAPHISTRY_USERNAME\"), password=os.getenv(\"GRAPHISTRY_PASSWORD\"))\n",
    "\n",
    "graph_engine = await get_graph_engine()\n",
    "\n",
    "graph_url = await render_graph(graph_engine.graph)\n",
    "print(graph_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e7dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search(\n",
    "    vector_engine,\n",
    "    collection_name: str,\n",
    "    query_text: str = None,\n",
    "):\n",
    "    query_vector = (await vector_engine.embedding_engine.embed_text([query_text]))[0]\n",
    "\n",
    "    connection = await vector_engine.get_connection()\n",
    "    collection = await connection.open_table(collection_name)\n",
    "\n",
    "    results = await collection.vector_search(query_vector).limit(10).to_pandas()\n",
    "\n",
    "    result_values = list(results.to_dict(\"index\").values())\n",
    "\n",
    "    return [dict(\n",
    "        id = str(result[\"id\"]),\n",
    "        payload = result[\"payload\"],\n",
    "        score = result[\"_distance\"],\n",
    "    ) for result in result_values]\n",
    "\n",
    "\n",
    "from cognee.infrastructure.databases.vector import get_vector_engine\n",
    "\n",
    "vector_engine = get_vector_engine()\n",
    "results = await search(vector_engine, \"entities\", \"sarah.nguyen@example.com\")\n",
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
